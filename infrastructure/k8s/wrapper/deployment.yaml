apiVersion: v1
kind: ConfigMap
metadata:
  name: wrapper-config
  namespace: ai
data:
  SYSTEM_PROMPT: |
    You are a professional interviewer. Keep replies brief, ask exactly one clear question at a time, and wait for the candidateâ€™s answer before asking the next. If the candidate is verbose, politely steer them to the point.
  MODEL: "llama3.1:8b-instruct-q5_K_M"
  MAX_TOKENS: "1000"
  TIMEOUT_MS: "30000"
  VLLM_URL: "http://ollama.ai.svc.cluster.local:11434/v1"
  OLLAMA_BASE: "http://ollama:11434"
---
apiVersion: v1
kind: Secret
metadata:
  name: wrapper-secret
  namespace: ai
type: Opaque
stringData:
  INTERNAL_KEY: "9d7h32Ghpq_!Bxm92JKj3kLvaL@8qYpf"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dv-wrapper
  namespace: ai
spec:
  replicas: 2
  selector:
    matchLabels: { app: dv-wrapper }
  template:
    metadata: { labels: { app: dv-wrapper } }
    spec:
      initContainers:
      - name: warmup-model
        image: curlimages/curl:8.8.0
        env:
        - name: MODEL
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: MODEL } }
        command:
        - sh
        - -lc
        - >
          echo "Warming up Ollama with $MODEL" &&
          curl -sS -X POST http://ollama.ai.svc.cluster.local:11434/api/pull
          -H "content-type: application/json"
          -d "{\"name\":\"$MODEL\"}" || true

      containers:
      - name: wrapper
        image: asia-south1-docker.pkg.dev/datavalley-383814/dv-ai/wrapper:v1
        ports: [{ containerPort: 3000 }]
        env:
        - name: VLLM_URL
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: VLLM_URL } }
        - name: MODEL
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: MODEL } }
        - name: SYSTEM_PROMPT
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: SYSTEM_PROMPT } }
        - name: TIMEOUT_MS
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: TIMEOUT_MS } }
        - name: MAX_TOKENS
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: MAX_TOKENS } }
        - name: INTERNAL_KEY
          valueFrom: { secretKeyRef: { name: wrapper-secret, key: INTERNAL_KEY } }
        - name: OLLAMA_BASE
          valueFrom: { configMapKeyRef: { name: wrapper-config, key: OLLAMA_BASE } }
        readinessProbe:
          httpGet:
            path: /healthz
            port: 3000
            httpHeaders:
              - name: Authorization
                value: "Bearer 9d7h32Ghpq_!Bxm92JKj3kLvaL@8qYpf"  # Internal Key for Probe
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /healthz
            port: 3000
            httpHeaders:
              - name: Authorization
                value: "Bearer 9d7h32Ghpq_!Bxm92JKj3kLvaL@8qYpf"  # Internal Key for Probe
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          requests:
            cpu: "250m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: dv-wrapper
  namespace: ai
spec:
  selector: { app: dv-wrapper }
  ports:
    - name: http
      port: 80
      targetPort: 3000
  type: ClusterIP
---
# temporary public LB; we'll switch to HTTPS Ingress later
apiVersion: v1
kind: Service
metadata:
  name: dv-wrapper-public
  namespace: ai
spec:
  selector: { app: dv-wrapper }
  type: LoadBalancer
  ports:
    - name: http
      port: 80
      targetPort: 3000
